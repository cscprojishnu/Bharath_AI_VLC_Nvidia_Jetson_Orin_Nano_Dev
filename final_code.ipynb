{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07fcaa7",
   "metadata": {},
   "source": [
    "# Touchless HCI for Media Control Using Hand Gestures (VLC)\n",
    "\n",
    "**Objective:**  \n",
    "Develop a real-time touchless Human–Computer Interaction (HCI) system using MediaPipe Hands to control VLC Media Player via hand gestures.\n",
    "\n",
    "**Key Features:**\n",
    "- MediaPipe Hands for hand landmark detection\n",
    "- Gesture-based VLC control using keyboard shortcuts\n",
    "- Real-time FPS, accuracy, and end-to-end latency measurement\n",
    "- Optimized for real-time performance (<200 ms latency)\n",
    "\n",
    "\n",
    "In Command Prompt type: \"C:\\Program Files\\VideoLAN\\VLC\\vlc.exe\" --extraintf http --http-port 8090 --http-password vlc123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54044582",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "Install and import all required libraries for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7429b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from pynput.keyboard import Controller, Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a81853",
   "metadata": {},
   "source": [
    "CELL 2 — VLC KEYBOARD CONTROL LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02871ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyboard = Controller()\n",
    "\n",
    "def send_vlc_key(gesture):\n",
    "    if gesture == \"play_pause\":\n",
    "        keyboard.press(Key.space)\n",
    "        keyboard.release(Key.space)\n",
    "\n",
    "    elif gesture == \"stop\":\n",
    "        keyboard.press('s')\n",
    "        keyboard.release('s')\n",
    "\n",
    "    elif gesture == \"volume_up\":\n",
    "        keyboard.press(Key.ctrl)\n",
    "        keyboard.press(Key.up)\n",
    "        keyboard.release(Key.up)\n",
    "        keyboard.release(Key.ctrl)\n",
    "\n",
    "    elif gesture == \"volume_down\":\n",
    "        keyboard.press(Key.ctrl)\n",
    "        keyboard.press(Key.down)\n",
    "        keyboard.release(Key.down)\n",
    "        keyboard.release(Key.ctrl)\n",
    "\n",
    "    elif gesture == \"next\":\n",
    "        keyboard.press('n')\n",
    "        keyboard.release('n')\n",
    "\n",
    "    elif gesture == \"previous\":\n",
    "        keyboard.press('p')\n",
    "        keyboard.release('p')\n",
    "\n",
    "    elif gesture == \"minimize\":\n",
    "        keyboard.press(Key.cmd)\n",
    "        keyboard.press(Key.down)\n",
    "        keyboard.release(Key.down)\n",
    "        keyboard.release(Key.cmd)\n",
    "\n",
    "    elif gesture == \"close\":\n",
    "        keyboard.press(Key.alt)\n",
    "        keyboard.press(Key.f4)\n",
    "        keyboard.release(Key.f4)\n",
    "        keyboard.release(Key.alt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f97d1",
   "metadata": {},
   "source": [
    "CELL 3 — MEDIAPIPE INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56eaa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ccec4",
   "metadata": {},
   "source": [
    "CELL 4 — GESTURE & FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bb7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_COOLDOWN = 0.25\n",
    "NAV_COOLDOWN = 1.2\n",
    "\n",
    "def distance(a, b):\n",
    "    return math.hypot(a.x - b.x, a.y - b.y)\n",
    "\n",
    "def get_finger_states(landmarks):\n",
    "    wrist = landmarks.landmark[0]\n",
    "    fingers = []\n",
    "\n",
    "    fingers.append(distance(landmarks.landmark[4], wrist)  > distance(landmarks.landmark[2], wrist)  * 1.15)\n",
    "    fingers.append(distance(landmarks.landmark[8], wrist)  > distance(landmarks.landmark[6], wrist)  * 1.15)\n",
    "    fingers.append(distance(landmarks.landmark[12], wrist) > distance(landmarks.landmark[10], wrist) * 1.15)\n",
    "    fingers.append(distance(landmarks.landmark[16], wrist) > distance(landmarks.landmark[14], wrist) * 1.15)\n",
    "    fingers.append(distance(landmarks.landmark[20], wrist) > distance(landmarks.landmark[18], wrist) * 1.15)\n",
    "\n",
    "    return [int(f) for f in fingers]\n",
    "\n",
    "def recognize_gesture(states, landmarks):\n",
    "    wrist = landmarks.landmark[0]\n",
    "    thumb_tip = landmarks.landmark[4]\n",
    "\n",
    "    if states == [1,1,1,1,1]:\n",
    "        return \"play_pause\"\n",
    "    if states == [0,0,0,0,0]:\n",
    "        return \"stop\"\n",
    "    if states == [1,0,0,0,0] and thumb_tip.y < wrist.y:\n",
    "        return \"volume_up\"\n",
    "    if states == [1,0,0,0,0] and thumb_tip.y > wrist.y:\n",
    "        return \"volume_down\"\n",
    "    if states == [1,1,0,0,1]:\n",
    "        return \"next\"\n",
    "    if states == [1,0,0,0,1]:\n",
    "        return \"previous\"\n",
    "    if states == [1,1,1,1,0]:\n",
    "        return \"minimize\"\n",
    "    if states == [1,1,1,0,1]:\n",
    "        return \"close\"\n",
    "    return \"unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573c287",
   "metadata": {},
   "source": [
    "CELL 5 — GESTURE STABILIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdc5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureStabilizer:\n",
    "    def __init__(self, frames=2):\n",
    "        self.history = []\n",
    "        self.frames = frames\n",
    "\n",
    "    def update(self, gesture):\n",
    "        self.history.append(gesture)\n",
    "        if len(self.history) > self.frames:\n",
    "            self.history.pop(0)\n",
    "        if self.history.count(gesture) == self.frames:\n",
    "            return gesture\n",
    "        return None\n",
    "\n",
    "stabilizer = GestureStabilizer(frames=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e1a65b",
   "metadata": {},
   "source": [
    "CELL 6 — CAMERA & PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256f3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touchless VLC Control Started | Focus VLC window | Press 'q' to exit\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "fps_start = time.time()\n",
    "fps_counter = 0\n",
    "fps = 0\n",
    "\n",
    "latency_ms = 0\n",
    "latency_start_time = None\n",
    "\n",
    "last_gesture = None\n",
    "last_action_time = 0\n",
    "\n",
    "total_gestures = 0\n",
    "valid_gestures = 0\n",
    "accuracy = 0\n",
    "\n",
    "TARGET_FPS = 18\n",
    "FRAME_DELAY = 1 / TARGET_FPS\n",
    "\n",
    "print(\"Touchless VLC Control Started | Focus VLC window | Press 'q' to exit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec16a",
   "metadata": {},
   "source": [
    "CELL 7 — MAIN EXECUTION LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8576f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    frame_start = time.time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # FPS\n",
    "    fps_counter += 1\n",
    "    if time.time() - fps_start >= 1:\n",
    "        fps = fps_counter\n",
    "        fps_counter = 0\n",
    "        fps_start = time.time()\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand = results.multi_hand_landmarks[0]\n",
    "        mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        states = get_finger_states(hand)\n",
    "        gesture = recognize_gesture(states, hand)\n",
    "        stable = stabilizer.update(gesture)\n",
    "\n",
    "        # ⏱️ Start END-TO-END latency timer when gesture becomes STABLE\n",
    "        if stable and latency_start_time is None:\n",
    "            latency_start_time = time.time()\n",
    "\n",
    "        if stable:\n",
    "            total_gestures += 1\n",
    "            if stable != \"unknown\":\n",
    "                valid_gestures += 1\n",
    "\n",
    "                now = time.time()\n",
    "                cooldown = NAV_COOLDOWN if stable in [\"next\", \"previous\"] else GENERAL_COOLDOWN\n",
    "\n",
    "                if (\n",
    "                    stable != \"unknown\"\n",
    "                    and (stable != last_gesture or stable in [\"next\", \"previous\"])\n",
    "                    and (now - last_action_time) > cooldown\n",
    "                ):\n",
    "                    send_vlc_key(stable)\n",
    "\n",
    "                    # ⏱️ End END-TO-END latency measurement\n",
    "                    if latency_start_time is not None:\n",
    "                        latency_ms = int((time.time() - latency_start_time) * 1000)\n",
    "                        latency_start_time = None\n",
    "\n",
    "                    last_gesture = stable\n",
    "                    last_action_time = now\n",
    "\n",
    "            accuracy = int((valid_gestures / total_gestures) * 100)\n",
    "\n",
    "            cv2.putText(frame, f\"Gesture: {stable}\", (10, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        stabilizer.history.clear()\n",
    "        last_gesture = None\n",
    "        latency_start_time = None\n",
    "\n",
    "    # ================= OVERLAYS =================\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Latency (E2E): {latency_ms} ms\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2)\n",
    "\n",
    "    cv2.putText(frame, f\"Accuracy: {accuracy}%\", (10, 90),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,200,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Touchless VLC Control\", frame)\n",
    "\n",
    "    elapsed = time.time() - frame_start\n",
    "    if elapsed < FRAME_DELAY:\n",
    "        time.sleep(FRAME_DELAY - elapsed)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "hands.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
